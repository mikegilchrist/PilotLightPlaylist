#!/usr/bin/env python3
# Purpose: Scrape Pilot Light upcoming events with refined parsing
# Usage: python pilotlight_scraper.py [--week_start N] [--week_stop M] [--verbose]
# Input:
#   --week_start: how many weeks from today to include (default: 0)
#   --week_stop: how many weeks ahead to stop (default: -1 = no limit)
# Output:
#   Writes upcoming events to "upcoming_artists_ALL.txt" or dated file
# Date: 2025-08-04
# Version: 1.4.9
# Chat name: PilotLight Scraper Refinement
# GPT Model: OpenAI o4-mini
# Attribution: Generated by Michael Gilchrist in collaboration with ChatGPT

import argparse
import logging
import re
from datetime import datetime, timedelta

import requests
from bs4 import BeautifulSoup

# ——— CLI & Logging —————————————————————————————————————————————
parser = argparse.ArgumentParser(description="Scrape Pilot Light upcoming events")
parser.add_argument("--week_start", type=int, default=0,
                    help="Weeks from today to start (default: 0)")
parser.add_argument("--week_stop", type=int, default=-1,
                    help="Weeks from today to stop (default: no limit)")
parser.add_argument("--verbose", "-v", action="store_true",
                    help="Enable debug output")
args = parser.parse_args()

level = logging.DEBUG if args.verbose else logging.INFO
logging.basicConfig(format="%(message)s", level=level)
log = logging.getLogger()

# ——— Date Range —————————————————————————————————————————————————
today = datetime.today().date()
start_date = today + timedelta(weeks=args.week_start)
end_date = None if args.week_stop < 0 else today + timedelta(weeks=args.week_stop)

# ——— Constants —————————————————————————————————————————————————
URL = "https://thepilotlight.com"
IGNORE_PHRASES = {"OUT SERIES", "UPDATE", "UPDATE!", "IMPROVISED MUSIC SETS"}

# ——— Helpers —————————————————————————————————————————————————
def parse_event(p_tag):
    # remove any <s>…</s> struck text
    for strike in p_tag.find_all("s"):
        strike.decompose()

    text = p_tag.get_text(separator="\n")
    # normalize dashes
    text = text.replace("\u2013", "-").replace("\u2014", "-")
    # collapse spaces/tabs but keep newlines
    text = re.sub(r"[ \t]+", " ", text)

    # look for “Day Month Day# … $PRICE”
    m = re.search(r"(\w+day)\s+([A-Za-z]+)\s+(\d+).*?\$(FREE|\d+)",
                  text, flags=re.IGNORECASE)
    if not m:
        log.debug("No date/price match in:\n%s\n", text)
        return None

    # build “Month Day Year” string
    month, day, price = m.group(2), m.group(3), m.group(4).upper()
    date_str = f"{month} {day} {today.year}"

    # try both abbreviated and full month names
    show_date = None
    for fmt in ("%b %d %Y", "%B %d %Y"):
        try:
            show_date = datetime.strptime(date_str, fmt).date()
            break
        except ValueError:
            continue
    if show_date is None:
        log.warning("Date parse error: '%s' (from: %s)", date_str, text)
        return None

    # filter by date range
    if show_date < start_date:
        log.debug("Skipping (too early): %s", show_date)
        return None
    if end_date and show_date > end_date:
        log.debug("Skipping (too late): %s", show_date)
        return None

    # extract lines and look for ALL-CAP names (allow digits and &)
    bands = []
    for line in text.split("\n"):
        line = line.strip()
        if not line or any(phrase in line.upper() for phrase in IGNORE_PHRASES):
            continue
        # split on common delimiters
        for part in re.split(r"\bwith\b|,|/| and ", line, flags=re.IGNORECASE):
            part = part.strip()
            # allow uppercase letters, digits, spaces, ampersands
            if re.fullmatch(r"[A-Z0-9 &]{2,}", part):
                bands.append(part)

    if not bands:
        log.debug("No bands found in:\n%s\n", text)
        return None

    return f"{show_date} | {', '.join(bands)} | ${price}"

# ——— Main Flow —————————————————————————————————————————————————
resp = requests.get(URL)
resp.raise_for_status()
soup = BeautifulSoup(resp.text, "html.parser")

events = []
for p in soup.find_all("p"):
    ev = parse_event(p)
    if ev:
        log.info("Parsed event: %s", ev)
        events.append(ev)

# output
out_file = (
    "upcoming_artists_all.txt"
    if args.week_stop < 0
    else f"upcoming_artists_{today:%Y-%m-%d}.txt"
)
with open(out_file, "w", encoding="utf-8") as fp:
    for e in events:
        fp.write(e + "\n")

if args.week_stop < 0:
    log.info("Wrote %d events ➔ %s", len(events), out_file)
else:
    start_lbl = start_date.strftime("%b %d")
    end_lbl = (end_date - timedelta(days=1)).strftime("%b %d")
    log.info("Wrote %d events ➔ %s", len(events), out_file)
    log.info("Suggested playlist title: Pilot Light Shows %s–%s", start_lbl, end_lbl)
